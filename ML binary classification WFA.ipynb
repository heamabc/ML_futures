{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score\n",
    "\n",
    "from ml_function import *\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport ml_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of ml_function failed: Traceback (most recent call last):\n",
      "  File \"D:\\Miniconda\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"ml_function.py\", line 206\n",
      "    tmp_tmp_true_and_pred.append(tmp_true_and_pred.iloc[abcdefg - difference,1])\n",
      "                        ^\n",
      "IndentationError: expected an indented block\n",
      "]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736cb8eba2eb4de58500428ea5b2b83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSd0ZXN0X251bScsIG1heD0xLCBzdHlsZT1Qcm9ncmVzc1N0eWxlKGRlc2NyaXB0aW9uX3dpZHRoPXUnaW7igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587ef3f7e39944aba7b8dcfc3f70d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdjb2RlbGlzdCcsIG1heD0zNywgc3R5bGU9UHJvZ3Jlc3NTdHlsZShkZXNjcmlwdGlvbl93aWR0aD11J2nigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78346b99ce541b29d37dd049837aa02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdNTCcsIG1heD0yOTcxLCBzdHlsZT1Qcm9ncmVzc1N0eWxlKGRlc2NyaXB0aW9uX3dpZHRoPXUnaW5pdGnigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c2eeae42364aee85b47489efb029a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdNTCcsIG1heD05NzMsIHN0eWxlPVByb2dyZXNzU3R5bGUoZGVzY3JpcHRpb25fd2lkdGg9dSdpbml0aWHigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ad5f34e2df78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mdata_wf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_wf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_percentage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_and_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                 \u001b[0mtmp_true_and_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_true_and_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Echo Kwan\\ml_function.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(data_wf, test_percentage, test_num, isper, method, params, opt_and_train, benchmark, regression)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mmax_drawdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cumulative_rtn\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcum_rtn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"annualized_rtn\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannualized_rtn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"annualized_volatility\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannualized_volatility\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, iteration, feval)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda\\lib\\site-packages\\xgboost\\core.pyc\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#periodic prediction and optimization\n",
    "#train and optimize dataset at the same date for all product\n",
    "\n",
    "#general parameters\n",
    "isper = False\n",
    "method = \"xgboost\"\n",
    "test_percentage = 0.1\n",
    "encore = False\n",
    "regression = False\n",
    "clipping = False\n",
    "clip_benchmark = 0.0\n",
    "rtn_period = 5\n",
    "\n",
    "#opt params\n",
    "#if opt_and_train = True, test_num is the period for opt_and_train\n",
    "optimize = True\n",
    "opt_freq = 5\n",
    "opt_and_train = True\n",
    "\n",
    "#ML params\n",
    "if regression == True:\n",
    "    params = {\"eta\":0.1, \"objective\": \"reg:sqauredlogerror\",\n",
    "              'n_estimators': 1000, 'max_depth': 4, 'min_child_weight': 0.5, \"gamma\":0,\n",
    "              'colsample_bytree': 0.2, 'subsample': 0.2, \"n_jobs\": -1, \"verbosity\": 0}\n",
    "else:\n",
    "    params = {\"eta\":0.1, \"objective\": \"binary:logistic\",\n",
    "              'n_estimators': 1000, 'max_depth': 4, 'min_child_weight': 0.5, \"gamma\":0,\n",
    "              'colsample_bytree': 0.2, 'subsample': 0.2, \"n_jobs\": -1, \"verbosity\": 0}\n",
    "benchmark = 0.5\n",
    "train_size = 252\n",
    "\n",
    "#initialize variables\n",
    "codelist, output, true_and_pred, period_list, accuracy, precision, recall, f1, r2= initialize()\n",
    "\n",
    "\n",
    "#prevent error\n",
    "if opt_and_train == True:\n",
    "    isper = False\n",
    "\n",
    "#ML enginedate\n",
    "for test_num in tqdm([20], desc=\"test_num\"):\n",
    "    \n",
    "    n_samples = train_size + test_num\n",
    "    for k in tqdm(range(codelist.shape[0]), desc=\"codelist\"):        \n",
    "        product_name = str(codelist.iloc[k,0])\n",
    "        data = extract_data(codelist, k, regression, clipping, clip_benchmark)\n",
    "        length, test_length, steps = wf(data, n_samples, test_percentage, test_num, isper)\n",
    "        \n",
    "        #generate opt_marker\n",
    "        if product_name == \"305\":\n",
    "            tmplist = []\n",
    "\n",
    "            for abcdefg in range(output.shape[0] - data.shape[0] + train_size):\n",
    "                tmplist.append(None)\n",
    "\n",
    "            for abcdefg in range(output.shape[0] - (output.shape[0] - data.shape[0] + 252)):\n",
    "                if abcdefg % test_num == 0:\n",
    "                    tmplist.append(1)\n",
    "                else:\n",
    "                    tmplist.append(0)\n",
    "            opt_marker = pd.Series(tmplist)\n",
    "        \n",
    "        tmp_true_and_pred = pd.DataFrame()\n",
    "        \n",
    "        #start ML\n",
    "        na_count = output.shape[0] - data.shape[0]\n",
    "        for i in tqdm(range(data.shape[0]+test_num), desc = \"ML\"):\n",
    "            if opt_marker.iloc[i+na_count-test_num] == 1 and i >= n_samples:\n",
    "                if i <= data.shape[0]:\n",
    "                    data_wf = data.iloc[i-n_samples:i]\n",
    "                else:\n",
    "                    data_wf = data.iloc[i-n_samples:]\n",
    "                y_test, model = build_model(data_wf, test_percentage, test_num, isper, method, params, opt_and_train, benchmark, regression)\n",
    "                tmp_true_and_pred = tmp_true_and_pred.append(y_test, ignore_index=True)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        #reshaping to same length\n",
    "        tmp_true_and_pred = tmp_true_and_pred.drop(\"index\", axis=1)\n",
    "        \n",
    "        if regression == True:\n",
    "            tmp_true_and_pred[product_name+\"_signal\"] = [1 if x>= benchmark else -1 if x < -benchmark else 0 for x in tmp_true_and_pred[product_name+\"_prediction\"]]\n",
    "            order = []\n",
    "            order.append(tmp_true_and_pred.columns[0])\n",
    "            order.append(tmp_true_and_pred.columns[2])\n",
    "            order.append(tmp_true_and_pred.columns[1])\n",
    "            tmp_true_and_pred[order]\n",
    "        else:\n",
    "            tmp_true_and_pred[product_name] = [1 if x == 1 else -1 if x == 0 else 0 for x in tmp_true_and_pred[product_name]]\n",
    "        tmp_true_and_pred.reset_index(drop=True)\n",
    "\n",
    "        if true_and_pred.shape[0] > tmp_true_and_pred.shape[0]:\n",
    "            for abc in range(true_and_pred.shape[0] - tmp_true_and_pred.shape[0]):\n",
    "                tmp_true_and_pred.index+=1\n",
    "        true_and_pred = pd.concat([true_and_pred,tmp_true_and_pred], axis=1)\n",
    "\n",
    "        if regression == True:\n",
    "            r2.append(r2_score(tmp_true_and_pred.iloc[:,0].dropna(), tmp_true_and_pred.iloc[:,2].dropna()))\n",
    "        else:\n",
    "            accuracy.append(accuracy_score(tmp_true_and_pred.iloc[:,0].dropna(), tmp_true_and_pred.iloc[:,1].dropna()))\n",
    "            precision.append(precision_score(tmp_true_and_pred.iloc[:,0].dropna(), tmp_true_and_pred.iloc[:,1].dropna()))\n",
    "            recall.append(recall_score(tmp_true_and_pred.iloc[:,0].dropna(), tmp_true_and_pred.iloc[:,1].dropna()))\n",
    "            f1.append(f1_score(tmp_true_and_pred.iloc[:,0].dropna(), tmp_true_and_pred.iloc[:,1].dropna()))\n",
    "\n",
    "        \n",
    "        #calculate daily return\n",
    "\n",
    "        tmp_output = calc_rtn(product_name, tmp_true_and_pred, k, opt_marker, rtn_period)\n",
    "        \n",
    "        if tmp_output.shape[0] < output.shape[0]:\n",
    "            for abcdefg in range(output.shape[0] - tmp_output.shape[0]):\n",
    "                tmp_output.index += 1\n",
    "        \n",
    "        output = pd.concat([output,tmp_output], axis=1)\n",
    "\n",
    "        \n",
    "    date = output[\"date\"]\n",
    "    #calculate the sumyield of the portfolio\n",
    "    output, rtn, cumrtn = calc_sumyield(output, date, codelist)\n",
    "\n",
    "    #metrics calculator\n",
    "    metrics =  calc_metrics(rtn,cumrtn, accuracy, r2, regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0 - preds)\n",
    "    return grad, hess\n",
    "\n",
    "beta = 0.5\n",
    "def weighted_logloss(preds, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    p = 1.0/(1.0 + np.exp(-preds))\n",
    "    grad = p * (beta + y-beta*y) - y\n",
    "    hess = p * (1-p) * (beta + y - beta * y)\n",
    "    return grad, hess\n",
    "\n",
    "lamda = 0.1\n",
    "def general_logloss(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0/(1.0 + np.exp(-preds))\n",
    "    grad = preds - labels + lamda * (preds - obj_series)\n",
    "    hess = preds * (1.0 - preds) + lamda * (preds * (1.0 - preds))\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(r'D:\\QuantChina\\ML\\backtest_10_features_252+20_oo_xgbcv.xlsx', engine='xlsxwriter')\n",
    "output.to_excel(writer, sheet_name = \"data\", index=False)\n",
    "true_and_pred.to_excel(writer, sheet_name = \"true_and_pred\", index=False)\n",
    "rtn.to_excel(writer, sheet_name = \"daily_rtn\", index=False)\n",
    "cumrtn.to_excel(writer, sheet_name = \"cumulative_rtn\", index=False)\n",
    "metrics.to_excel(writer, sheet_name = \"metrics\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(r\"D:\\QuantChina\\ML\\testing.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
